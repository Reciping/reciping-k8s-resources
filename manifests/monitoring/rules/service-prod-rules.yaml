apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: service-prod-rules
  namespace: monitoring
spec:
  groups:
    # 1) 가용성/오류율
    - name: http-availability
      rules:
        - alert: ServiceErrorRateHighWarning
          expr: |
            (
              sum by (reciping_team,reciping_service) (
                rate(http_server_requests_seconds_count{status=~"5..",uri!~"/actuator/.*"}[5m])
              )
              /
              sum by (reciping_team,reciping_service) (
                rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m])
              )
            ) > 0.05
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "[경고] 5xx 오류율 높음"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 5xx 오류율이 10분 동안 5%를 초과했습니다."

        - alert: ServiceErrorRateHighCritical
          expr: |
            (
              sum by (reciping_team,reciping_service) (
                rate(http_server_requests_seconds_count{status=~"5..",uri!~"/actuator/.*"}[5m])
              )
              /
              sum by (reciping_team,reciping_service) (
                rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m])
              )
            ) > 0.10
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "[치명] 5xx 오류율 매우 높음"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 5xx 오류율이 5분 동안 10%를 초과했습니다."

        - alert: ServiceInstancesDown
          expr: |
            min by (reciping_team,reciping_service) (up{namespace="reciping"}) == 0
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "[치명] 모든 인스턴스 다운"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 모든 스크레이프 대상이 Down 상태입니다."

    # 2) 지연 시간 (퍼센타일)
    - name: http-latency
      rules:
        - alert: ServiceLatencyP95High
          expr: |
            histogram_quantile(0.95,
              sum by (le,reciping_team,reciping_service) (
                rate(http_server_requests_seconds_bucket{uri!~"/actuator/.*"}[5m])
              )
            ) > 0.5
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "[경고] P95 지연 시간 높음 (>500ms)"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 P95 지연이 10분 동안 500ms를 초과했습니다."

        - alert: ServiceLatencyP99High
          expr: |
            histogram_quantile(0.99,
              sum by (le,reciping_team,reciping_service) (
                rate(http_server_requests_seconds_bucket{uri!~"/actuator/.*"}[5m])
              )
            ) > 1
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "[치명] P99 지연 시간 매우 높음 (>1s)"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 P99 지연이 5분 동안 1초를 초과했습니다."

    # 3) 트래픽/에러율 이상 감지(베이스라인 대비 편차)
    - name: http-anomaly
      rules:
        - alert: ServiceTrafficAnomaly
          expr: |
            (
              sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m]))
              -
              avg_over_time((
                sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m]))
              )[1h])
            )
            /
            clamp_min(stddev_over_time((
              sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m]))
            )[1h]), 1e-6)
            > 3
            and
            sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m])) > 0.1
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "[경고] 트래픽 이상 감지"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 RPS가 최근 1시간 기준선 대비 3σ 이상 벗어났습니다(10분 지속)."

        - alert: ServiceErrorRateAnomaly
          expr: |
            (
              (
                sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{status=~"5..",uri!~"/actuator/.*"}[5m]))
                /
                sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m]))
              )
              -
              avg_over_time((
                (
                  sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{status=~"5..",uri!~"/actuator/.*"}[5m]))
                  /
                  sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m]))
                )
              )[1h])
            )
            /
            clamp_min(stddev_over_time((
              (
                sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{status=~"5..",uri!~"/actuator/.*"}[5m]))
                /
                sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m]))
              )
            )[1h]), 1e-6)
            > 3
            and
            sum by (reciping_team,reciping_service) (rate(http_server_requests_seconds_count{uri!~"/actuator/.*"}[5m])) > 0.1
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "[경고] 오류율 이상 감지"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 오류율이 최근 1시간 기준선 대비 3σ 이상 벗어났습니다(10분 지속)."

    # 4) JVM/리소스(애플리케이션 관점)
    - name: jvm-and-runtime
      rules:
        - alert: JvmHeapUsageHigh
          expr: |
            max by (reciping_team,reciping_service) (
              jvm_memory_used_bytes{area="heap"}
              /
              jvm_memory_max_bytes{area="heap"}
            ) > 0.9
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "[경고] JVM Heap 사용률 높음 (>90%)"
            description: "팀={{ $labels.reciping_team }}, 서비스={{ $labels.reciping_service }}의 JVM Heap 사용률이 10분 동안 90%를 초과했습니다."

        - alert: ContainerRestarts
          expr: |
            (increase(kube_pod_container_status_restarts_total{namespace="reciping"}[5m]) > 0)
            and on (namespace,pod)
            group_left(reciping_team,reciping_service)
            max by (namespace,pod,reciping_team,reciping_service) (
              up{namespace="reciping", reciping_team!="", reciping_service!=""}
            )
          for: 0m
          labels:
            severity: warning
          annotations:
            summary: "[경고] 컨테이너 재시작 발생"
            description: "namespace=reciping, pod={{ $labels.pod }}, team={{ $labels.reciping_team }}, service={{ $labels.reciping_service }} 재시작 감지"

        # 임시 Raw 경보는 제거(팀/서비스 라벨이 없어서 라우팅 검증 외에는 불필요)
